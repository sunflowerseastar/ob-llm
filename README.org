* org-llm

Talk to LLMs from within Org mode by using babel code blocks.

#+begin_quote
NOTE: org-llm requires the [[https://github.com/simonw/llm][llm]] CLI tool
#+end_quote

org-llm interfaces with LLMs by wrapping ~llm~, a specific command line tool created by Simon Willison. Setting up ~llm~, configuring it, and understanding its interface are required. Please visit the documentation for ~llm~ [[https://llm.datasette.io/en/stable/setup.html][here]]. Also, capability with [[https://www.gnu.org/software/emacs/][GNU Emacs]], [[https://orgmode.org/][Org mode]], and [[https://orgmode.org/worg/org-contrib/babel/intro.html][Babel]] is assumed.

** Example

Using ~llm~ from the command line:

#+begin_src sh
llm -m 4o "Explain 'a person needs an LLM like a pelican needs a bicycle'"
#+end_src

Using org-llm from inside an Org-mode buffer:

#+begin_src org
,#+begin_src llm :model openai/gpt-4.1-mini
Explain 'a person needs an LLM like a pelican needs a bicycle'
,#+end_src
#+end_src

Then call ~org-ctrl-c-ctrl-c~ with the binding ~C-c C-c~.

* Features

Since this is a wrapper of the ~llm~ CLI tool, the feature set is mostly ~llm~'s feature set.

Features provided by ~llm~ (found [[https://github.com/simonw/llm][here]]):

- [[https://llm.datasette.io/en/stable/openai-models.html][model selection]] (including [[https://llm.datasette.io/en/stable/other-models.html][local models]]) and configuration
- local [[https://llm.datasette.io/en/stable/logging.html][sqlite storage]], easily navigable by [[https://github.com/simonw/datasette][datasette]], [[https://github.com/saulpw/visidata][visidata]], etc.
  - use arbitrary databases (ex. different DB per work project), or "no-log"
  - [[https://llm.datasette.io/en/stable/logging.html#searching-the-logs][search history]], [[https://llm.datasette.io/en/stable/usage.html#continuing-a-conversation][continue any conversation]]
- [[https://llm.datasette.io/en/stable/usage.html#executing-a-prompt][streaming]], [[https://llm.datasette.io/en/stable/usage.html#system-prompts][system prompts]], [[https://llm.datasette.io/en/stable/fragments.html][fragments]] (including web, URLs), [[https://llm.datasette.io/en/stable/usage.html#attachments][attachments]] (multi-modal)
- [[https://llm.datasette.io/en/stable/plugins/index.html][plugins]], [[https://llm.datasette.io/en/stable/schemas.html][schemas]], [[https://llm.datasette.io/en/stable/templates.html][templates]]

Features provided by org-llm:

- interface with ~llm~ from inside Org-mode buffers, passing Babel code block header arguments as flags
- supports async, streaming, and concurrent processes across multiple buffers
- finished responses are automatically converted to prettified JSON or Org mode:
  - ~schema~ and ~schema-multi~ responses are pretty-printed as JSON
  - other, general responses are converted from markdown to Org mode
  - NOTE: JSON pretty-printing requires [[https://jqlang.org/][jq]]; Org mode conversion requires [[https://pandoc.org/][Pandoc]]
  - NOTE: disable auto-conversion per prompt with a ~:no-conversion~ Babel code block header argument, or disable auto-conversion with a customization setting via ~(setq org-llm-post-process-auto-convert-p nil)~
- refresh ~llm~-ready models with ~org-llm-refresh-models~
- model helpers: copy (kill), paste (yank), see/set default model
- interactively search the ~llm~ logs database with ~org-llm-query-logs~
- mode-line indicator for when org-llm is in use
- immediate process termination with ~org-llm-kill-all-processes~

* General Usage

1. Enable with ~(org-llm-mode 1)~
2. Create an Org source block: ~#+begin_src llm :model "4o"...<body>...#+end_src~
3. Execute with ~C-c C-c~

** Code Block Header Arguments ("Params") Handling

The [[https://org-babel.readthedocs.io/en/latest/header-args/][header arguments]] for the Babel code blocks are a bit over-loaded in that they might be used (1) to control Org mode Babel code block evaluation behavior, (2) to control org-llm application behavior/settings, or otherwise (3) to be passed along as flags to the ~llm~ command.

1. *Org babel parameters* are consumed by Org mode, and thus not passed to LLM command: ~:results~, ~:exports~, ~:cache~, ~:noweb~, ~:session~, ~:tangle~, ~:hlines~, etc.
  - ~:results silent~ will emit to the output buffer, but the results will not be streamed or copied in to the org buffer (or post-processed).

2. *Custom org-llm parameters* are used for special handling, ex. ~:no-conversion~ to leave the completed response unaltered.

3. *All other parameters* are passed directly to the ~llm~ command as flags.

** Model Management

| ~org-llm-yank-a-model-name~    | Select a model from ~org-llm-models~ to paste              |
| ~org-llm-copy-a-model-name~    | Select a model from ~org-llm-models~ to kill               |
| ~org-llm-echo-default-model~   | Show the current default model in the echo area            |
| ~org-llm-change-default-model~ | Pick which model from ~org-llm-models~ to set as default   |
| ~org-llm-refresh-models~       | Update ~org-llm-models~ with the models available to ~llm~ |

** Conversation History

Search logs from the ~llm~ logs database with ~org-llm-query-logs~. Selecting one will copy (kill) the conversation ID, which can be used to then resume that conversation from any code block.

** Customization

- ~org-llm-output-buffer~ - Buffer name for displaying streaming output
- ~org-llm-mode-line-indicator~ - Text to display in mode line during active processes

| ~org-llm-line-indicator~                              | What to show in the mode line while a process is active. Default is "ðŸ¦†"                                 |
| ~org-llm-post-process-auto-convert-p~                 | Whether to convert completed responses to prettified JSON (schema) or Org mode (regular). Default is ~t~  |
| ~org-llm-models~                                      | Models available to yank, kill, and set as default. Update this by ~org-llm-refresh-models~, not manually |
| ~org-llm-pandoc-additional-org-mode-conversion-flags~ | Additional flags to pass to Pandoc when converting general responses to Org mode                         |

*** Converting Markdown to Pandoc

When a general response is finished (as opposed to a code block with header arguments of ~:schema~ or ~:schema-multi~ ([[https://llm.datasette.io/en/stable/schemas.html][docs]])), it is automatically converted to Org mode using [[https://pandoc.org/][Pandoc]]. This can be turned off for a single code block with a header argument of ~:no-conversion~, or as a customization by setting ~org-llm-post-process-auto-convert-p~ to ~nil~.

Personally, I do not want the Org mode PROPERTY drawers from the conversion, so I add a flag that ~org-llm~ should pass along to Pandoc:

#+begin_src emacs-lisp
(setq org-llm-pandoc-additional-org-mode-conversion-flags
      '("--lua-filter=/Users/myuser/.local/share/remove-header-attr.lua"))
#+end_src

And here are the contents of my ~remove-header-attr.lua~ file at that location:

#+begin_src lua
function Header (header)
  return pandoc.Header(header.level, header.content, pandoc.Attr())
end
#+end_src
